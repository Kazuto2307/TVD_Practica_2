{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b0R18qGjOxT"
   },
   "source": [
    "<center>\n",
    "<h1 style=\"font-family:verdana\">\n",
    " üíª üßë Reconeixement d'entitats anomenades üßë üíª\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZOmxM4_kAUC"
   },
   "source": [
    "<p> üéØ <b>Objectiu</b>: en aquesta segona part de la pr√†ctica aprendrem a recon√®ixer entitats anomenades, √©s a dir, identificar i classificar entitats en una oraci√≥ que poden ser (en el context de reserva de vols) la ciutat de sortida o d'arribada, la data del mes i el dia, si es de negocis o turista o altres categories espec√≠fiques. Aquesta tasca se sol plantejar etiquetant cada paraula amb una etiqueta de la categoria de l'entitat a la qual correspon.\n",
    "\n",
    "Tant la classificaci√≥ d'intencions (tasca estudiada a la primera part) com el reconeixement d'entitats anomenades (Name Entity Recognition, NER) que veurem en aquesta part s√≥n components crucials dels sistemes de processament del llenguatge natural (Natural Language Processing, NLP) i sovint s'utilitzen junts per crear aplicacions d'intel¬∑lig√®ncia artificial (IA) conversacionals m√©s sofisticades. Per exemple, en un xatbot, la classificaci√≥ d'intencions ajuda a entendre la intenci√≥ principal de l'usuari, mentre que el reconeixement d'entitats anomenades ajuda a extreure entitats rellevants per proporcionar respostes m√©s contextualitzades.\n",
    "\n",
    "\n",
    "<p> ‚ú® <b>Contingut</b>: els passos d'aquesta segona part seran similars a la primera. En primer lloc, analitzarem el conjunt de dades. En segon lloc, prepararem les dades per a poder entrenar el model. I finalment dissenyarem l'arquitectura i entrenarem el model. </p>\n",
    "\n",
    "\n",
    "<p> ‚úè <b>Exercicis</b>: en cada secci√≥ anireu trobant exercicis que haureu d'anar resolent. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI_K-e1cmXlb"
   },
   "source": [
    "---\n",
    "\n",
    "<h2> √çndex </h2>\n",
    "\n",
    "1. [Inspecci√≥ del conjunt de dades](#section-one)\n",
    "  * [Exercici 1](#ex-one)\n",
    "  * [Exercici 2](#ex-two)\n",
    "2. [Preprocessament de dades](#section-two)\n",
    "  * [Exercici 3](#ex-three)\n",
    "  * [Exercici 4](#ex-four)\n",
    "3. [Disseny del model i entrenament](#section-three)\n",
    "  * [Exercici 5](#ex-five)\n",
    "  * [Exercici 6](#ex-six)\n",
    "4. [Lliurable](#section-four)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6966,
     "status": "ok",
     "timestamp": 1729339827353,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "XKn_1FnTxvfV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swhc9NwqpUs8"
   },
   "source": [
    "<h1><a name=\"section-one\"> 1. Inspecci√≥ del conjunt de dades </a></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14600,
     "status": "ok",
     "timestamp": 1729339841949,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "SSM223cvp7wJ",
    "outputId": "76718690-7584-425f-ab61-15ed20854404"
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?id=1u2wzXvsuscLeFHwXcDwMDaNDy0u_99-t\"\n",
    "!tar -zxf nlu_ATIS_data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729339841949,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "OAp0lemwjd71",
    "outputId": "e876aa75-1712-44f0-e3e3-d88db575f468"
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqKtLqYUpWkZ"
   },
   "source": [
    "En aquesta segona part de la pr√†ctica utilitzarem el mateix dataset que a la primera part, per√≤ en aquest cas utilitzarem la **primera columna** que correspon a les **oracions** introdu√Ødes pels usuaris i la **segona columna** on trobarem les oracions d'entrada en format **BILOU**.\n",
    "\n",
    "El format BILOU  √©s un esquema d'etiquetatge que es fa servir a les tasques de reconeixement d'entitats anomenades. El nom *BILOU* representa les etiquetes utilitzades en aquest esquema:\n",
    "\n",
    "*   **B** - Beginning: primer token d'una entitat.\n",
    "*   **I** - Inside: token dins d'una entitat.\n",
    "*   **L** - Last: √∫ltim token de l'entitat.\n",
    "*   **O** - Outside: token que no pertany a cap entitat.\n",
    "*   **U** - Unit: entitats d'un sol token\n",
    "\n",
    "A continuaci√≥, carregarem les dades per visualitzar i poder entendre millor aquestes etiquetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fUGDuD9wUfm"
   },
   "source": [
    "---\n",
    "\n",
    " <h1><a name=\"ex-one\"><center> ‚úè Exercici 1 ‚úè</a></h1>\n",
    "\n",
    "A continuaci√≥ us demanem que carregueu els dos CSVs de la carpeta `data`: `train.csv`, `test.csv` utilitzant pandas. Recorda que aquests CSVs no tenen cap√ßalera. Agafeu les 900 √∫ltimes lineas del fitxer `train.csv` per crear un dataframe per validaci√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729339842514,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "36hvQo3GloN6",
    "outputId": "2d3eba39-f945-4789-e1e4-cbe765b381a5"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729339842515,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "93lI2dDVxmST",
    "outputId": "d0a460e8-21c5-4c45-cd82-3d5f0eb25fee"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#train_data = ...\n",
    "#val_data = ...\n",
    "#test_data = ...\n",
    "\n",
    "print('Training size:', len(train_data))\n",
    "print('Validation dataset size:', len(val_data))\n",
    "print('Test dataset size:', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CugYB4oNyFju"
   },
   "source": [
    "---\n",
    "\n",
    " <h1><a name=\"ex-two\"><center> ‚úè Exercici 2 ‚úè</a></h1>\n",
    "\n",
    "Tal com hem introdu√Øt abans, per a aquest exercici ens centrarem en la **primera** i la **segona** columna. Per tant, ara us demanem que guardeu en les seg√ºents variables, les llistes corresponents a les oracions i a les etiquetes de les tres particions (`train`, `validation` i `test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729339842515,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "edw3mK_Hy-M3",
    "outputId": "b57ed5d1-7219-4806-af3c-4629fbb5f5ed"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#train_sentences = ...\n",
    "#train_labels = ...\n",
    "\n",
    "#val_sentences = ...\n",
    "#val_labels = ...\n",
    "\n",
    "#test_sentences = ...\n",
    "#test_labels = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKgiGo7UzYDU"
   },
   "source": [
    "---\n",
    "\n",
    "Si tot ha anat b√© ja podem analitzar quin aspecte t√© el format BILOU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729339842515,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "lgjKAyCUzp_M",
    "outputId": "378a6225-456b-4e5f-d8fb-b14ababe1d74"
   },
   "outputs": [],
   "source": [
    "print(train_sentences[5])\n",
    "print(train_labels[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWzA_MPL02kk"
   },
   "source": [
    "Aquest hauria de ser el resultat obtingut si executeu la cel¬∑la anterior:\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\n",
    " \"O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day\"\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "En aquest exemple, `boston` i `838 am` corresponen a l'entitat \"ciutat de sortida\" i a l'entitat \"hora de sortida\" respectivament (`fromloc.city_name`,`depart_time.time`). `838` correspon al primer token que pertany la entitat `depart_time.time` i `am` al segon de la mateixa entitat. Els tokens com `i` o `want` no pertanyen a cap entitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729339842515,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "7BuHmIx62MUA",
    "outputId": "27503c1e-11e3-486f-a72b-ed784b186dae"
   },
   "outputs": [],
   "source": [
    "print(train_sentences[1])\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSWlVauS2gll"
   },
   "source": [
    "I aquest hauria de ser el resultat de la cel¬∑la anterior:\n",
    "\n",
    "```\n",
    "what flights are available from pittsburgh to baltimore on thursday morning\n",
    " O O O O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.day_name B-depart_time.period_of_day\n",
    "```\n",
    "\n",
    "En l'anterior exemple, `what`, `flights`, `are`, `available`, `from`, `to` i `on` estan etiquetades com a no pertanyents a cap entitat. I, en canvi, `pittsburgh` pertany a l'entitat d'un sol token anomenada ciutat d'arribada (`toloc.city_name`). Tamb√© hi ha entitats compostes com `baltimore` que pertany a l'entitat ciutat de sortida (`fromloc.city_name`) i `thursday morning` que pertanyen a les entitats data de sortida (`depart_date.day_name`, `depart_time.period_of_day`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hwZtqaI7rOQ"
   },
   "source": [
    "Vegem-ne la llista completa d'entitats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1729339842912,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "2VDzOwWk4Ee2",
    "outputId": "8ba5bb79-8345-4cab-fbf2-d1ecb46c0fa4"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_unique_entities(list_of_label_sentences):\n",
    "  flat_labels = []\n",
    "  for labels in list_of_label_sentences:\n",
    "    flat_labels += labels.split()\n",
    "  c = Counter(flat_labels)\n",
    "  return len(c), list(c.keys())\n",
    "\n",
    "num_unique_entities, unique_entities = count_unique_entities(train_labels)\n",
    "\n",
    "print(\"Number of different entities:\", num_unique_entities)\n",
    "\n",
    "print(\"Unique entities:\", unique_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wlsgR88_D8g"
   },
   "source": [
    "<h1><a name=\"section-two\"> 2. Preprocessament de dades </a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8yM79_n_OPA"
   },
   "source": [
    "El processament de les dades ser√† semblant al de la primera part d'aquesta pr√†ctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLrvW1frMus9"
   },
   "source": [
    "---\n",
    "\n",
    " <h1><a name=\"ex-three\"><center> ‚úè Exercici 3 ‚úè</a></h1>\n",
    "\n",
    "En aquest exercici us demanem que realitzeu els passos seg√ºents per preparar les dades.\n",
    "\n",
    " 1. El primer pas ser√† construir el vocabulari a partir de les paraules presents a les oracions d'entrenament.\n",
    "\n",
    "2. El segon pas ser√† convertir les oracions en seq√º√®ncies de nombres enters usant el tokenitzador.\n",
    "\n",
    "3. El tercer pas ser√† guardar la longitud original de cada oraci√≥. Aix√≤ ens ser√† √∫til per evaluar el nostre model sense tenir en compte el padding.\n",
    "\n",
    "3. Finalment, per aconseguir que totes les seq√º√®ncies tinguen la mateixa longitud, fixarem la longitud segons la m√†xima trobada a l'entrenament i afegirem zeros a les oracions de menor longitud.\n",
    "\n",
    "Recordeu que podeu consultar com fer-ho a la documentaci√≥ de la llibrer√≠a:\n",
    "* <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\"> Tokenizer </a>\n",
    "* <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\"> Pad Sequences </a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729339842912,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "e0zOvP3UI_CE"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#tokenizer = ...\n",
    "\n",
    "#train_sequences = ...\n",
    "#max_sequence_length = ...\n",
    "#len_train_sequences = ...\n",
    "#train_pad_sequences = ...\n",
    "\n",
    "#val_sequences = ...\n",
    "#len_val_sequences = ...\n",
    "#val_pad_sequences = ...\n",
    "\n",
    "#test_sequences = ...\n",
    "#len_test_sequences = ...\n",
    "#test_pad_sequences = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729339842912,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "UQPTc0CyOzLh",
    "outputId": "11200186-8274-4c8a-f948-9e119d71305b"
   },
   "outputs": [],
   "source": [
    "train_pad_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n55MNuHfMegM"
   },
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wNo-X61OyRc"
   },
   "source": [
    "Tal com vam fer a la primera part, aqu√≠ tamb√© hem de convertir les diferents classes d'entitats en vectors one-hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD9_A1RJP1LZ"
   },
   "source": [
    "---\n",
    "\n",
    " <h1><a name=\"ex-four\"><center> ‚úè Exercici 4 ‚úè</a></h1>\n",
    "\n",
    "Per aconseguir-ho haureu de seguir els passos seg√ºents.\n",
    "\n",
    " 1. En primer lloc, haureu d'esbrinar quantes etiquetes diferents hi ha. Podeu prendre com a exemple la funci√≥ `count_unique_entities` per fer-ho. Tingueu en compte que haureu de modificar la funci√≥, ja que per exemple aquesta funci√≥ considera que `B-depart_time.time`, `I-depart_time.time`, `L-depart_time.time`, `U-depart_time.time` s√≥n la mateixa entitat. En aquest exercici, necessitarem comptar-les per separat. Tamb√© l'entitat O ha de ser considerada com una classe.\n",
    "\n",
    " 2. El segon pas ser√† codificar les diferents classes trobades en etiquetes num√®riques. Tingueu en compte que cada paraula de l'oraci√≥ t√© una etiqueta i, per tant, per a cada oraci√≥ tindrem una llista d'etiquetes. El *padding* el codificarem amb l'etiqueta corresponent a **O** (outside). Per ajudar-vos hem preparat el processament per a les etiquetes d'entrenament, intenteu comprendre el que es fa i aix√≠ repetir-ho per a la partici√≥ de validaci√≥ i test.\n",
    "\n",
    " 3. Finalment, haureu de convertir les diferents classes a vectors one-hot. Recordeu de nou que per a cada oraci√≥ tindrem una llista de vectors one-hot.\n",
    "\n",
    "\n",
    " Podeu consultar els apartats de la documentaci√≥:\n",
    " * <a href=https://www.tensorflow.org/guide/keras/understanding_masking_and_padding> Masking and Padding </a>\n",
    "\n",
    " * <a href=https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical> To Categorical </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 3003,
     "status": "error",
     "timestamp": 1729339845912,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "Xl8GyFz4MgY3",
    "outputId": "534922cc-2c49-4b35-a3e2-c6c387128a4f"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Step 1\n",
    "#def count_unique_entities(list_of_label_sentences):\n",
    "    #...\n",
    "\n",
    "    #return len(unique_entities), unique_entities\n",
    "\n",
    "#num_unique_entities, unique_entities = count_unique_entities(train_labels)\n",
    "\n",
    "#print(\"Number of different entities:\", num_unique_entities)\n",
    "#print(\"Unique entities:\", unique_entities)\n",
    "\n",
    "#Step 2\n",
    "#label_encoder = ...\n",
    "#train_numerical_labels = ...\n",
    "#train_pad_labels = ...\n",
    "\n",
    "def remove_sentences(list_labels, list_sequences):\n",
    "  idx_to_remove = []\n",
    "  labels_to_remove = []\n",
    "  for idx, labels in enumerate(list_labels):\n",
    "    for label in labels:\n",
    "      if label not in unique_entities:\n",
    "        idx_to_remove.append(idx)\n",
    "        labels_to_remove.append(label)\n",
    "\n",
    "  labels = [elem for i, elem in enumerate(list_labels) if i not in idx_to_remove]\n",
    "  sequences = [elem for i, elem in enumerate(list_sequences) if i not in idx_to_remove]\n",
    "  return labels, np.array(sequences)\n",
    "\n",
    "#_test_labels = [label.split() for label in test_labels]\n",
    "#test_labels, test_pad_sequences = remove_sentences(_test_labels, test_pad_sequences)\n",
    "#test_numerical_labels = ...\n",
    "#test_pad_labels = ...\n",
    "\n",
    "#val_numerical_labels =\n",
    "#val_pad_labels =\n",
    "\n",
    "\n",
    "#Step 3\n",
    "#train_labels_one_hot = ...\n",
    "#test_labels_one_hot = ...\n",
    "#val_labels_one_hot = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "975GjI0tp7_9"
   },
   "source": [
    "<h1><a name=\"section-three\"> 3. Disseny del model i entrenament </a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMY7LjpHv7GZ"
   },
   "source": [
    "---\n",
    "<h1><a name=\"ex-five\"><center> ‚úè Exercici 5 ‚úè</a></h1>\n",
    "\n",
    "De forma similar com f√©reu a la primera part de la pr√†ctica us demanem que dissenyeu l'arquitectura i entreneu el model. Podeu fer servir una arquitectura similar. Ara b√©, per capturar les depend√®ncies seq√ºencials podeu canviar la capa de GlobalMaxPooling1D per una LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "O8Ed4x77t_4d"
   },
   "outputs": [],
   "source": [
    "s = train_pad_labels.shape\n",
    "train_flat_labels = train_pad_labels.reshape(s[0]*s[1])\n",
    "train_unq_labels = np.unique(train_flat_labels)\n",
    "print(train_flat_labels.shape, train_unq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "XMPaZzX4sdH4"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                keras.layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.pos_emb(positions)\n",
    "        token_embeddings = self.token_emb(inputs)\n",
    "        return token_embeddings + position_embeddings\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "PcWiSLm3nvdW"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#embedding_dim = ...\n",
    "#vocab_size = ...\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add()\n",
    "#model.add()\n",
    "#model.add()\n",
    "\n",
    "#model.compile()\n",
    "\n",
    "# Train the model\n",
    "#batch_size = ...\n",
    "#epochs = ...\n",
    "#model.fit()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "#loss, accuracy = model.evaluate()\n",
    "#print(f\"Test accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "-ts_03xMaADp"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "4cP_IiZFmFK8"
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "nxFoy2UBktFS"
   },
   "outputs": [],
   "source": [
    "def preds_to_index(preds, seq_lens):\n",
    "  '''\n",
    "  Turn predictions to numerical indexes, flatten the sentences and discard padding.\n",
    "  '''\n",
    "  idx_preds = []\n",
    "  for pred, seq_len in zip(preds,seq_lens):\n",
    "      for l in range(seq_len):\n",
    "        idx_preds.append(np.argmax(pred[l]))\n",
    "  return idx_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeVIzSA4NYgD"
   },
   "source": [
    "Com ja sabeu, NER es una tasca on les dades estan molt desbalancejades. La gran majoria de les nostres etiquetes ser√°n 'O' (outside). Es pot donar el cas on el model tingui una accuracy molt alta predint sempre 'O'.\n",
    "\n",
    "Per mesurar millor com de b√≥ √©s el nostre model, calcularem la F1 score per cada classe, aix√≠ com la mitjana (macro average). Quan prepareu el vostre document, heu de reportar aquesta mitjana com a m√®trica del vostre model, no l'acuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "f4DL7Tota13v"
   },
   "outputs": [],
   "source": [
    "test_labels_idx = preds_to_index(test_labels_one_hot,len_test_sequences)\n",
    "preds_idx = preds_to_index(preds, len_test_sequences)\n",
    "\n",
    "print(classification_report(test_labels_idx, preds_idx, zero_division=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VArxTPJgEaTx"
   },
   "source": [
    "A continuaci√≥ podeu veure algunes prediccions del model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1729339845913,
     "user": {
      "displayName": "Jordi Luque",
      "userId": "10816317814088701546"
     },
     "user_tz": -120
    },
    "id": "_S4H2EqYmiqs"
   },
   "outputs": [],
   "source": [
    "probs = model.predict(test_pad_sequences)\n",
    "_predicted_labels = np.argmax(probs, axis=2)\n",
    "\n",
    "predicted_labels = [list(label_encoder.inverse_transform(label)) for label in _predicted_labels]\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print('Sentence: ', test_sentences[i])\n",
    "    print('Original label: ', test_labels[i])\n",
    "    print('Predicted label: ', predicted_labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65EQLymROmPX"
   },
   "source": [
    "---\n",
    "\n",
    " <h1><a name=\"ex-six\"><center> ‚úè Exercici 6 ‚úè </a></h1>\n",
    "\n",
    "Modifiqueu els seg√ºents par√†metres del model anterior i analitzeu com afecten a la seva *accuracy*:\n",
    "\n",
    " 1. **Mida dels Embeddings.** Proveu diferents mides d'*Embeddings* i observeu com canvia l'*accuracy* del model. Heu d'explicar les vostres conclusions.\n",
    "\n",
    " 2. **Xarxes Convolucionals.** Afegiu capes convolucionals al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥ a l'hora d'escollir-los. Recordeu, que tamb√© podeu provar diferents configuracions de *pooling*.\n",
    "\n",
    " 3. **Xarxes Recurrents.**  Afegiu capes recurrents al vostre model (LSTM, GRU). Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥.\n",
    "\n",
    " 4. ** Transformer.** Afegiu blocs de Transformer al vostre model. Expliqueu amb detall els valors que heu provat i la vostra motivaci√≥.\n",
    "\n",
    " 5. **Regularitzaci√≥.** Quan proveu configuracions amb m√©s par√†metres veureu que el model comen√ßa a tenir *overfitting* molt prompte durant l'entrenament. Afegiu *Dropout* al vostre model. Heu d'explicar la vostra decisi√≥ de valors i de posici√≥ dins de la xarxa.\n",
    "\n",
    "\n",
    " 6. **Balancejat de les classes.** Si analitzeu el dataset, veureu que la freq√º√®ncia de les classes est√† molt desbalancejada. Keras us permet afegir un pes per a cada classe a l'hora de calcular la loss (Mireu el par√†metre \"class_weigth\" a la documentaci√≥ https://keras.io/api/models/model_training_apis/). Calculeu un pes per a cada classe i afegiu-lo al m√®tode fit del vostre model.\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr2eNm7qJr4F"
   },
   "source": [
    "---\n",
    "\n",
    "<h1><a name=\"section-four\"> 4. Lliurable </a></h1>\n",
    "\n",
    "Heu d'entregar un document PDF de com a **m√†xim 10 p√†gines** que incloga els resultats de tots els exercicis aix√≠ com una explicaci√≥ de cadascun dels resultats i de la modificaci√≥ que heu fet. L'estructura del document √©s:\n",
    "\n",
    "1. Introducci√≥.\n",
    "2. Experiments i Resultats (amb raonament).\n",
    "3. Conclusions.\n",
    "\n",
    "No cal que afegiu el vostre codi al document, podeu entregar el *notebook* juntament amb el document.\n",
    "\n",
    " ---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TVD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
